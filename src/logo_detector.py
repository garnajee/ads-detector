#!/usr/bin/env python3

import cv2
import numpy as np
import os
from pathlib import Path
from typing import List, Tuple, Optional, Dict
import time
import logging
import statistics

# Assuming data_models.py and utils.py are in the same 'src' package
from .data_models import DetectionPoint, SuspiciousInterval
from .utils import seconds_to_hms

class LogoDetector:
    """
    D√©tecteur de logo optimis√© pour analyser des vid√©os longues.
    Version v6 avec deuxi√®me passe performante, validation de dur√©e minimum,
    et affinement pr√©cis des transitions.
    """

    def __init__(self, logo_dataset_path: str, logo_coords: Tuple[int, int, int, int]):
        """
        Initialise le d√©tecteur de logo.

        Args:
            logo_dataset_path: Chemin vers le dossier contenant les logos PNG
            logo_coords: Tuple (x, y, width, height) de la position du logo dans la vid√©o
        """
        self.logo_dataset_path = Path(logo_dataset_path)
        self.logo_x, self.logo_y, self.logo_width, self.logo_height = logo_coords
        self.logo_templates = []
        self.logo_masks = []
        self.threshold = 0.65

        # Param√®tres pour la gestion des cas limites
        self.merge_gap_threshold = 10.0  # Temps en secondes pour fusionner des segments proches
        self.black_screen_threshold = 15 # Moyenne d'intensit√© pour √©cran noir
        self.white_screen_threshold = 240 # Moyenne d'intensit√© pour √©cran blanc

        # Param√®tres pour l'analyse intelligente
        self.detection_history: List[DetectionPoint] = []
        self.ad_intervals_stats: Dict[str, float] = {}
        self.anomaly_threshold_multiplier = 2.0  # Seuil d'anomalie (√ó √©cart-type)
        self.second_pass_density_multiplier = 4
        self.min_ad_interval = 300  # Intervalle minimum attendu entre pubs (5 min) - pour stats
        self.max_expected_ad_interval = 1800  # Intervalle maximum normal (30 min) - pour stats

        # Dur√©e minimum pour un segment publicitaire
        self.min_ad_duration = 60  # 60 secondes minimum par d√©faut

        # Optimisations pour la deuxi√®me passe
        self.adaptive_threshold_enabled = True
        self.confidence_boost_threshold = 0.55

        # Configuration de logging
        # Le logger est g√©n√©ralement configur√© dans main.py ou au niveau de l'application.
        # Ici, on s'assure d'utiliser un logger nomm√©.
        self.logger = logging.getLogger(__name__)
        # self.logger.setLevel(logging.INFO) # Le niveau est mieux g√©r√© par la config globale.

        self.video_duration = 0.0 # Sera d√©fini lors de l'analyse

        # using cached templates
        self.cache_path = Path("cache_templates.npz")
        if self.cache_path.exists():
            self._load_from_cache()
        else:
            self._load_logo_templates()
            self._save_to_cache()

    def _load_logo_templates(self):
        """Charge tous les templates de logos depuis le dataset."""
        self.logger.info(f"Chargement des templates de logos depuis {self.logo_dataset_path}")
        logo_files = list(self.logo_dataset_path.glob("*.png"))

        if not logo_files:
            self.logger.error(f"Aucun fichier PNG trouv√© dans {self.logo_dataset_path}")
            raise ValueError(f"Aucun fichier PNG trouv√© dans {self.logo_dataset_path}")

        max_templates = min(300, len(logo_files)) # Limiter le nombre de templates charg√©s
        for i, logo_file in enumerate(logo_files[:max_templates]):
            try:
                template = cv2.imread(str(logo_file), cv2.IMREAD_GRAYSCALE)
                if template is not None:
                    if template.shape != (self.logo_height, self.logo_width):
                        template = cv2.resize(template, (self.logo_width, self.logo_height))
                    self.logo_templates.append(template)
                    mask = np.where(template > 20, 255, 0).astype(np.uint8)
                    self.logo_masks.append(mask)
            except Exception as e:
                self.logger.warning(f"Erreur lors du chargement de {logo_file}: {e}")
                continue
            if (i + 1) % 100 == 0 or (i + 1) == max_templates :
                 self.logger.info(f"Charg√© {i+1}/{max_templates} templates")


        self.logger.info(f"Templates charg√©s: {len(self.logo_templates)}")
        if not self.logo_templates:
            self.logger.error("Aucun template de logo valide n'a pu √™tre charg√©.")
            raise ValueError("Aucun template de logo valide n'a pu √™tre charg√©")

    def _save_to_cache(self):
        # Sauvegarde tous les templates et masques en .npz
        np.savez_compressed(
            self.cache_path,
            *self.logo_templates,
            # on s√©pare templates et masks en deux groupes de variables arr_0‚Ä¶arr_N
        )
        np.savez_compressed(
            Path("cache_masks.npz"),
            *self.logo_masks
        )

    def _load_from_cache(self):
        # Charge le fichier .npz
        data_t = np.load(self.cache_path)
        self.logo_templates = [data_t[f] for f in data_t.files]
        data_m = np.load("cache_masks.npz")
        self.logo_masks = [data_m[f] for f in data_m.files]

    def _extract_logo_region(self, frame: np.ndarray) -> Optional[np.ndarray]:
        """Extrait la r√©gion du logo depuis une frame."""
        if frame is None:
            return None
        if len(frame.shape) == 3:
            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            frame_gray = frame

        # V√©rifier si les coordonn√©es sont valides pour la taille de l'image
        frame_h, frame_w = frame_gray.shape[:2]
        if self.logo_y + self.logo_height > frame_h or \
           self.logo_x + self.logo_width > frame_w:
            self.logger.warning(f"Les coordonn√©es du logo ({self.logo_x}, {self.logo_y}, {self.logo_width}, {self.logo_height}) sont en dehors des dimensions de la frame ({frame_w}x{frame_h}).")
            return None # Ou g√©rer autrement, e.g., en ajustant

        logo_region = frame_gray[
            self.logo_y:self.logo_y + self.logo_height,
            self.logo_x:self.logo_x + self.logo_width
        ]
        return logo_region

    def _is_extreme_screen(self, frame: np.ndarray) -> str:
        """D√©tecte si l'√©cran est compl√®tement noir, blanc ou normal."""
        if frame is None: return 'normal'
        if len(frame.shape) == 3:
            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            frame_gray = frame

        mean_intensity = np.mean(frame_gray)
        variance = np.var(frame_gray)

        if mean_intensity < self.black_screen_threshold and variance < 100: # Variance faible pour √©crans unis
            return 'black'
        elif mean_intensity > self.white_screen_threshold and variance < 100:
            return 'white'
        else:
            return 'normal'

    def _is_logo_present(self, logo_region: Optional[np.ndarray], full_frame: Optional[np.ndarray] = None,
                        analysis_pass: int = 1) -> Tuple[bool, float]:
        """D√©termine si le logo est pr√©sent dans la r√©gion extraite."""
        if logo_region is None or logo_region.size == 0:
            return False, 0.0

        if full_frame is not None:
            screen_type = self._is_extreme_screen(full_frame)
            if screen_type in ['black', 'white']:
                return False, 0.0
        
        if np.mean(logo_region) < 5: # R√©gion du logo trop sombre
            return False, 0.0

        best_match = 0.0
        positive_matches = 0
        confidence_scores = []
        
        max_templates_to_test = len(self.logo_templates)
        if analysis_pass == 2:
            max_templates_to_test = min(len(self.logo_templates), 200)
        else:
            max_templates_to_test = min(len(self.logo_templates), 100)

        for i, (template, mask) in enumerate(zip(self.logo_templates[:max_templates_to_test],
                                               self.logo_masks[:max_templates_to_test])):
            try:
                result = cv2.matchTemplate(logo_region, template, cv2.TM_CCOEFF_NORMED, mask=mask)
                _, max_val, _, _ = cv2.minMaxLoc(result) # Obtenir la valeur max de similarit√©
                confidence_scores.append(max_val)
                if max_val > best_match:
                    best_match = max_val
                if max_val > 0.5: # Seuil arbitraire pour compter un "match positif"
                    positive_matches +=1
            except cv2.error as e:
                # self.logger.warning(f"Erreur cv2.matchTemplate (template {i}): {e}. R√©gion: {logo_region.shape}, Template: {template.shape}")
                # Cela peut arriver si la r√©gion du logo est plus petite que le template √† cause d'un redimensionnement ou crop.
                # S'assurer que logo_region a au moins la taille de template.
                # Pour l'instant, on ignore ce template pour ce frame.
                continue


            if analysis_pass == 1 and best_match > 0.85 : break # Arr√™t anticip√© en passe 1
            if best_match > 0.9 : break # Arr√™t anticip√© si tr√®s bon match


        avg_confidence = np.mean(confidence_scores) if confidence_scores else 0.0
        confidence = max(best_match, avg_confidence * 1.2) # Score de confiance composite

        if analysis_pass == 2 and self.adaptive_threshold_enabled:
            if confidence > self.confidence_boost_threshold:
                confidence = min(1.0, confidence * 1.1)

        effective_threshold = self.threshold
        if analysis_pass == 2:
            effective_threshold *= 0.95 # Un peu plus permissif en 2e passe

        if best_match > effective_threshold:
            return True, confidence
        
        # Logique de d√©cision alternative bas√©e sur le ratio de matchs positifs
        match_ratio = positive_matches / len(self.logo_templates[:max_templates_to_test]) if max_templates_to_test > 0 else 0
        
        # Crit√®res plus souples pour la deuxi√®me passe
        if analysis_pass == 2:
            if match_ratio > 0.12 and best_match > 0.52: # Ajuster ces seuils si n√©cessaire
                return True, confidence
        else: # Premi√®re passe
            if match_ratio > 0.15 and best_match > 0.55: # Ajuster ces seuils si n√©cessaire
                return True, confidence

        return False, confidence

    def _analyze_detection_patterns(self) -> Dict[str, float]:
        """Analyse les patterns de d√©tection pour identifier les anomalies."""
        self.logger.info("Analyse des patterns de d√©tection...")
        ad_timestamps = [dp.timestamp for dp in self.detection_history if not dp.logo_present and dp.analysis_pass == 1]

        if len(ad_timestamps) < 2:
            self.logger.warning("Pas assez de publicit√©s d√©tect√©es (passe 1) pour l'analyse statistique des intervalles.")
            # Fournir des valeurs par d√©faut pour √©viter les erreurs si stats est utilis√© plus tard
            return {
                'mean_interval': self.min_ad_interval * 2, # Estimation grossi√®re
                'std_interval': self.min_ad_interval,
                'median_interval': self.min_ad_interval * 2,
                'min_interval': self.min_ad_interval,
                'max_interval': self.max_expected_ad_interval,
                'total_ads': len(ad_timestamps),
                'intervals_count': 0
            }

        intervals = np.diff(sorted(ad_timestamps))
        if len(intervals) == 0: # Moins de 2 pubs
            self.logger.warning("Pas assez d'intervalles entre publicit√©s pour statistiques.")
            return {
                'mean_interval': self.min_ad_interval * 2,
                'std_interval': self.min_ad_interval,
                'median_interval': self.min_ad_interval * 2,
                'min_interval': min(intervals) if len(intervals)>0 else self.min_ad_interval,
                'max_interval': max(intervals) if len(intervals)>0 else self.max_expected_ad_interval,
                'total_ads': len(ad_timestamps),
                'intervals_count': len(intervals)
            }

        stats = {
            'mean_interval': statistics.mean(intervals) if intervals.size > 0 else self.min_ad_interval * 2,
            'std_interval': statistics.stdev(intervals) if len(intervals) > 1 else self.min_ad_interval,
            'median_interval': statistics.median(intervals) if intervals.size > 0 else self.min_ad_interval * 2,
            'min_interval': min(intervals) if intervals.size > 0 else self.min_ad_interval,
            'max_interval': max(intervals) if intervals.size > 0 else self.max_expected_ad_interval,
            'total_ads': len(ad_timestamps),
            'intervals_count': len(intervals)
        }
        self.logger.info(f"Statistiques des intervalles publicitaires (bas√©es sur passe 1):")
        self.logger.info(f"  - Moyenne: {stats['mean_interval']/60:.1f} min, M√©diane: {stats['median_interval']/60:.1f} min")
        self.logger.info(f"  - √âcart-type: {stats['std_interval']/60:.1f} min, Min-Max: {stats['min_interval']/60:.1f} - {stats['max_interval']/60:.1f} min")
        return stats

    def _identify_suspicious_intervals(self, stats: Dict[str, float]) -> List[SuspiciousInterval]:
        """Identifie les intervalles suspects o√π des publicit√©s ont pu √™tre manqu√©es."""
        self.logger.info("Identification des intervalles suspects...")
        suspicious_intervals = []
        
        # Utiliser la m√©diane comme base plus robuste que la moyenne si possible, sinon la moyenne.
        # Si la std est tr√®s grande, la moyenne peut √™tre trompeuse.
        base_interval_for_expectation = stats.get('median_interval', stats.get('mean_interval', self.min_ad_interval * 1.5))
        if base_interval_for_expectation <=0: # Sanity check
             base_interval_for_expectation = self.min_ad_interval * 1.5


        anomaly_threshold = base_interval_for_expectation + (stats.get('std_interval', self.min_ad_interval) * self.anomaly_threshold_multiplier)
        anomaly_threshold = max(anomaly_threshold, self.max_expected_ad_interval, base_interval_for_expectation * 1.5) # Assurer un seuil minimum raisonnable

        self.logger.info(f"Seuil d'anomalie pour les gaps: > {anomaly_threshold/60:.1f} min (bas√© sur intervalle de {base_interval_for_expectation/60:.1f} min)")

        # Consid√©rer tous les points de d√©tection (logo pr√©sent ou non) pour d√©finir les "gaps" de non-publicit√©
        # Les "ads" sont o√π logo_present == False.
        # Un "gap suspect" est un long segment o√π logo_present == True entre deux pubs,
        # ou avant la premi√®re pub / apr√®s la derni√®re pub.

        ad_detections = sorted([dp for dp in self.detection_history if not dp.logo_present and dp.analysis_pass == 1], key=lambda x: x.timestamp)

        # Points de r√©f√©rence incluant le d√©but et la fin de la vid√©o
        reference_points = [0.0] + [dp.timestamp for dp in ad_detections] + [self.video_duration]
        reference_points = sorted(list(set(reference_points))) # Uniques et tri√©s

        for i in range(len(reference_points) - 1):
            start_gap = reference_points[i]
            end_gap = reference_points[i+1]
            gap_duration = end_gap - start_gap

            # Est-ce un gap de "programme" (entre deux pubs, ou avant/apr√®s pub)?
            # Si start_gap est 0 (d√©but video) et end_gap est la 1ere pub, c'est un gap de programme potentiel.
            # Si start_gap est une pub et end_gap est la pub suivante, c'est un gap de programme.
            # Si start_gap est la derni√®re pub et end_gap est la fin video, c'est un gap de programme.
            
            # On s'int√©resse aux longs segments SANS pub.
            # Ad_detections sont les moments o√π il y a pub.
            # Un intervalle [ad_detections[j].timestamp, ad_detections[j+1].timestamp] est un intervalle entre d√©buts de pub.
            # Ce n'est pas ce qu'on veut.
            # On veut les intervalles o√π le LOGO EST PR√âSENT pendant longtemps.

            # Repensons:
            # On a des detection_points. Certains sont logo_present=True, d'autres False.
            # Un suspicious interval est une longue p√©riode o√π logo_present=True, qui exc√®de l'attente.

            # It√©rons sur les transitions logo_absent -> logo_present et logo_present -> logo_absent
            # Ou plus simple: it√©rer sur les segments o√π le logo EST PR√âSENT.
            
            last_ad_end_time = 0.0
            if not ad_detections: # Pas de pub du tout, toute la vid√©o est suspecte si elle est longue
                if self.video_duration > anomaly_threshold :
                     expected_ads = max(1, int(self.video_duration / base_interval_for_expectation))
                     priority = (self.video_duration / base_interval_for_expectation) * expected_ads
                     suspicious_intervals.append(SuspiciousInterval(0, self.video_duration, expected_ads, 0, self.video_duration, priority))
                     self.logger.info(f"Aucune pub d√©tect√©e, toute la vid√©o ({self.video_duration/60:.1f} min) est suspecte.")
                # else :
                #     self.logger.info("Aucune pub d√©tect√©e, vid√©o courte, pas d'analyse suspecte approfondie.")

            for idx, ad in enumerate(ad_detections):
                # Segment de programme avant la premi√®re pub
                if idx == 0 and ad.timestamp > anomaly_threshold:
                    duration_prog = ad.timestamp
                    expected_ads_missed = max(1, int(duration_prog / base_interval_for_expectation) -1) # -1 car on s'attend √† une pub √† la fin
                    if expected_ads_missed > 0:
                        priority = (duration_prog / base_interval_for_expectation) * expected_ads_missed
                        suspicious_intervals.append(SuspiciousInterval(0, ad.timestamp, expected_ads_missed, 0, duration_prog, priority))
                        self.logger.info(f"Intervalle suspect (d√©but vid√©o): {seconds_to_hms(0)} -> {seconds_to_hms(ad.timestamp)} (dur√©e: {duration_prog/60:.1f}min, pubs attendues: {expected_ads_missed})")
                
                # Segment de programme entre deux pubs
                if idx < len(ad_detections) - 1:
                    current_ad_timestamp = ad.timestamp # D√©but de la pub actuelle
                    # Pour trouver la fin de la pub actuelle, il faudrait avoir les segments pr√©cis.
                    # Pour l'instant, on va se baser sur le d√©but de la pub suivante.
                    # Ceci est une approximation pour identifier les gaps de programme.
                    # L'id√©al serait d'avoir les *fins* des pubs de la passe 1.
                    # Pour simplifier, on consid√®re l'intervalle entre les *d√©buts* de d√©tection de non-logo.
                    # Si le temps entre le d√©but de pub N et d√©but de pub N+1 est tr√®s grand...
                    
                    # Alternative: utiliser tous les points de d√©tection_history
                    # Trouver les segments o√π logo_present == True
                    # Si un tel segment est > anomaly_threshold, il est suspect.
                    # Cette logique est d√©j√† plus ou moins dans la formation des intervalles finaux.

                    # Restons sur la logique originale : gaps entre pubs d√©tect√©es.
                    # La "fin" d'une pub est le timestamp du point de d√©tection o√π le logo est revenu.
                    # Mais ad_detections ne contient que les points o√π logo_present = False.

                    # On va consid√©rer le "gap" comme le temps entre la fin implicite d'une pub et le d√©but de la suivante.
                    # Pour la passe 1, les "pubs" sont des points.
                    # Le gap est entre dp_pub1 et dp_pub2.
                    next_ad = ad_detections[idx+1]
                    gap_prog_duration = next_ad.timestamp - ad.timestamp # Ceci est en fait la dur√©e (pub + programme)
                    
                    # On cherche les LONGUES p√©riodes de PROGRAMME (logo pr√©sent)
                    # On doit identifier les blocs de programme.
                    # Les `ad_detections` sont des points o√π le logo est absent.
                    # On cherche des intervalles [t1, t2] o√π `logo_present` est `True` pendant longtemps.
                    # Le code original se basait sur les `DetectionPoint` o√π `not dp.logo_present`.
                    # C'est correct : un long intervalle entre deux `not dp.logo_present` signifie
                    # que le logo a √©t√© pr√©sent (ou non analys√©) pendant cette dur√©e.

                    gap_duration_between_ads = next_ad.timestamp - ad.timestamp # Temps entre d√©but pub N et d√©but pub N+1
                    if gap_duration_between_ads > anomaly_threshold:
                        # On s'attend √† `gap / base_interval` pubs au total dans ce segment.
                        # On en a d√©tect√© 2 (les bornes). Donc `(gap / base_interval) - 2` pubs manqu√©es.
                        # Si base_interval est la dur√©e typique prog + pub.
                        expected_ads_in_gap = max(1, int(gap_duration_between_ads / base_interval_for_expectation) -1) # -1 car on a la pub au d√©but de next_ad
                        if expected_ads_in_gap > 0:
                            priority = (gap_duration_between_ads / base_interval_for_expectation) * expected_ads_in_gap
                            # Le segment suspect est entre la fin de la pub actuelle et le d√©but de la pub suivante.
                            # On n'a pas la "fin" de la pub 'ad'. On a son 'timestamp'.
                            # Pour la deuxi√®me passe, on analyse [ad.timestamp, next_ad.timestamp]
                            suspicious_intervals.append(SuspiciousInterval(
                                ad.timestamp, # On pourrait tenter d'affiner le d√©but
                                next_ad.timestamp, # On pourrait tenter d'affiner la fin
                                expected_ads_in_gap, 0, gap_duration_between_ads, priority))
                            self.logger.info(f"Intervalle suspect (entre pubs): {seconds_to_hms(ad.timestamp)} -> {seconds_to_hms(next_ad.timestamp)} (dur√©e: {gap_duration_between_ads/60:.1f}min, pubs attendues: {expected_ads_in_gap}, prio: {priority:.1f})")

                last_ad_end_time = ad.timestamp # Approximation: le point de d√©tection de la pub

            # Segment de programme apr√®s la derni√®re pub
            if ad_detections:
                last_ad = ad_detections[-1]
                duration_prog_end = self.video_duration - last_ad.timestamp
                if duration_prog_end > anomaly_threshold:
                    expected_ads_missed = max(1, int(duration_prog_end / base_interval_for_expectation) -1)
                    if expected_ads_missed > 0:
                        priority = (duration_prog_end / base_interval_for_expectation) * expected_ads_missed
                        suspicious_intervals.append(SuspiciousInterval(last_ad.timestamp, self.video_duration, expected_ads_missed, 0, duration_prog_end, priority))
                        self.logger.info(f"Intervalle suspect (fin vid√©o): {seconds_to_hms(last_ad.timestamp)} -> {seconds_to_hms(self.video_duration)} (dur√©e: {duration_prog_end/60:.1f}min, pubs attendues: {expected_ads_missed})")
        
        suspicious_intervals.sort(key=lambda x: x.priority, reverse=True)
        self.logger.info(f"Total d'intervalles suspects identifi√©s pour 2e passe: {len(suspicious_intervals)}")
        return suspicious_intervals

    def _perform_targeted_analysis(self, cap: cv2.VideoCapture, suspicious_intervals: List[SuspiciousInterval]) -> List[DetectionPoint]:
        """Effectue une analyse cibl√©e des intervalles suspects avec une densit√© accrue."""
        self.logger.info("D√©but de la deuxi√®me passe d'analyse cibl√©e optimis√©e...")
        new_detections = []
        fps = cap.get(cv2.CAP_PROP_FPS)

        for idx, interval in enumerate(suspicious_intervals):
            self.logger.info(f"Analyse cibl√©e {idx+1}/{len(suspicious_intervals)}: "
                           f"{seconds_to_hms(interval.start_time)} -> "
                           f"{seconds_to_hms(interval.end_time)} "
                           f"(priorit√©: {interval.priority:.1f})")

            duration = interval.end_time - interval.start_time
            base_density = self.second_pass_density_multiplier
            density_factor = base_density
            
            if interval.priority > 8: density_factor = base_density * 3
            elif interval.priority > 5: density_factor = base_density * 2.5
            elif interval.priority > 3: density_factor = base_density * 2
            else: density_factor = base_density * 1.5

            if duration > 2400: sample_interval_sec = 15 / density_factor
            elif duration > 1800: sample_interval_sec = 12 / density_factor
            elif duration > 900: sample_interval_sec = 10 / density_factor
            elif duration > 300: sample_interval_sec = 8 / density_factor
            else: sample_interval_sec = 6 / density_factor
            
            sample_interval_sec = max(sample_interval_sec, 1.0) # Au moins 1 sec pour la 2e passe dense
            sample_interval_frames = int(sample_interval_sec * fps)

            self.logger.info(f"  Densit√© d'√©chantillonnage 2e passe: {sample_interval_sec:.1f}s ({sample_interval_frames} frames)")

            current_time = interval.start_time
            points_analyzed_in_interval = 0
            while current_time < interval.end_time:
                frame_num = int(current_time * fps)
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
                ret, frame = cap.read()
                if not ret: break

                logo_region = self._extract_logo_region(frame)
                logo_present, confidence = self._is_logo_present(logo_region, frame, analysis_pass=2)
                
                new_detections.append(DetectionPoint(
                    timestamp=current_time, frame_number=frame_num,
                    logo_present=logo_present, confidence=confidence, analysis_pass=2
                ))
                points_analyzed_in_interval+=1
                if not logo_present:
                    self.logger.debug(f"  Nouvelle absence de logo d√©tect√©e en 2e passe √† {seconds_to_hms(current_time)} (conf: {confidence:.2f})")

                current_time += sample_interval_sec
                if points_analyzed_in_interval % 50 == 0:
                    self.logger.info(f"  Progression analyse intervalle: {((current_time - interval.start_time)/duration)*100 if duration > 0 else 0:.1f}%")
            self.logger.info(f"  Analyse intervalle termin√©e: {points_analyzed_in_interval} points.")


        self.logger.info(f"Deuxi√®me passe termin√©e. Nouveaux points de d√©tection: {len(new_detections)}")
        return new_detections

    def _get_frame_at_timestamp(self, cap: cv2.VideoCapture, timestamp: float) -> Optional[np.ndarray]:
        """R√©cup√®re une frame √† un timestamp donn√©."""
        # Pourrait √™tre d√©plac√© dans video_processing.py
        cap.set(cv2.CAP_PROP_POS_MSEC, timestamp * 1000)
        ret, frame = cap.read()
        return frame if ret else None

    def _binary_search_logo_transition(self, cap: cv2.VideoCapture,
                                     start_time: float, end_time: float,
                                     logo_present_at_start_of_search_range: bool,
                                     precision: float = 0.3) -> float:
        """
        Recherche binaire pour trouver le moment exact de transition du logo.
        Args:
            start_time: D√©but de la plage de recherche.
            end_time: Fin de la plage de recherche.
            logo_present_at_start_of_search_range: √âtat du logo au d√©but de la plage `start_time`.
                                                Si True, on cherche quand le logo dispara√Æt.
                                                Si False, on cherche quand le logo r√©appara√Æt.
            precision: Pr√©cision souhait√©e en secondes.
        Returns:
            Timestamp exact de la transition (d√©but du NOUVEL √©tat).
        """
        # Pourrait √™tre d√©plac√© dans video_processing.py
        low = start_time
        high = end_time
        transition_point = end_time # Par d√©faut, si aucune transition n'est trouv√©e dans la plage.

        # Sanity check: si start et end sont trop proches ou invalides
        if (high - low) <= precision:
            # On v√©rifie l'√©tat √† 'high' pour voir s'il est diff√©rent de l'√©tat de d√©part.
            # Ceci est important si la plage est d√©j√† plus petite que la pr√©cision.
            frame = self._get_frame_at_timestamp(cap, high)
            if frame is not None:
                logo_region = self._extract_logo_region(frame)
                # Utiliser la passe 2 pour _is_logo_present pour la pr√©cision
                logo_present_at_high, _ = self._is_logo_present(logo_region, frame, analysis_pass=2)
                if logo_present_at_high != logo_present_at_start_of_search_range:
                    return high # La transition est √† 'high' ou juste avant.
            return low if logo_present_at_start_of_search_range else high # Pas de changement d√©tectable, retourne le d√©but de l'√©tat

        while (high - low) > precision:
            mid_time = (low + high) / 2
            if mid_time <= low or mid_time >=high: # Eviter boucle infinie si pr√©cision trop fine
                break
            frame = self._get_frame_at_timestamp(cap, mid_time)
            if frame is None: # Ne peut pas lire la frame, on ne peut pas diviser la recherche ici.
                              # On pourrait essayer de se d√©caler un peu, ou arr√™ter.
                              # Pour l'instant, on arr√™te la recherche pour cette branche.
                self.logger.warning(f"Binary search: Impossible de lire la frame √† {mid_time:.2f}s. Arr√™t de l'affinement pour cette branche.")
                break 

            logo_region = self._extract_logo_region(frame)
            # Utiliser la passe 2 pour _is_logo_present pour la pr√©cision lors de l'affinement
            current_logo_state, _ = self._is_logo_present(logo_region, frame, analysis_pass=2)

            if current_logo_state == logo_present_at_start_of_search_range:
                # Le logo est toujours dans l'√©tat initial √† mid_time, donc la transition est plus loin.
                low = mid_time
            else:
                # Le logo a chang√© d'√©tat √† mid_time ou avant. La transition est dans [low, mid_time].
                high = mid_time
                # transition_point = mid_time # high devient notre meilleur candidat pour la transition

        # 'high' est maintenant le premier point o√π l'√©tat du logo est diff√©rent de celui √† start_time.
        # Ou si aucune transition trouv√©e, 'high' sera rest√© 'end_time'.
        # On veut le d√©but du *nouvel* √©tat.
        # Si on cherchait la disparition (True -> False), 'high' est le d√©but de False.
        # Si on cherchait la r√©apparition (False -> True), 'high' est le d√©but de True.
        return high


    def _merge_close_intervals(self, intervals: List[Tuple[float, float]]) -> List[Tuple[float, float]]:
        """Fusionne les intervalles d'absence de logo qui sont s√©par√©s par moins de merge_gap_threshold secondes."""
        if not intervals: return []
        
        # Trier par temps de d√©but
        sorted_intervals = sorted(intervals, key=lambda x: x[0])
        merged = [list(sorted_intervals[0])] # Utiliser une liste pour la modification

        for current_start, current_end in sorted_intervals[1:]:
            last_start, last_end = merged[-1]
            if current_start - last_end <= self.merge_gap_threshold: # Si le d√©but actuel est proche de la fin pr√©c√©dente
                merged[-1][1] = max(last_end, current_end) # Fusionner: √©tendre la fin du segment pr√©c√©dent
                self.logger.info(f"Fusion d'intervalles proches: {seconds_to_hms(last_end)} et {seconds_to_hms(current_start)} (√©cart: {current_start - last_end:.1f}s)")
            else:
                merged.append([current_start, current_end])
        
        return [tuple(item) for item in merged]


    def _filter_minimum_duration_intervals(self, intervals: List[Tuple[float, float]],
                                         video_duration: float) -> List[Tuple[float, float]]:
        """Filtre les intervalles pour ne conserver que ceux qui respectent la dur√©e minimum,
           sauf pour intro/outro."""
        if not intervals: return []
        
        filtered_intervals = []
        # Trier les intervalles par temps de d√©but pour identifier correctement intro/outro
        sorted_intervals = sorted(intervals, key=lambda x: x[0])

        for i, (start, end) in enumerate(sorted_intervals):
            duration = end - start
            is_first_segment = (i == 0 and start < 300) # Premier segment dans les 5 premi√®res minutes
            is_last_segment = (i == len(sorted_intervals) - 1 and (video_duration - end) < 300) # Dernier dans les 5 derni√®res minutes

            if duration <=0: # Ignorer les segments de dur√©e nulle ou n√©gative
                self.logger.warning(f"Intervalle de dur√©e nulle ou n√©gative ignor√©: {seconds_to_hms(start)} -> {seconds_to_hms(end)}")
                continue

            if is_first_segment or is_last_segment:
                filtered_intervals.append((start, end))
                segment_type = "intro" if is_first_segment else "outro"
                self.logger.info(f"Segment {segment_type} conserv√© (pas de dur√©e min): {seconds_to_hms(start)} -> {seconds_to_hms(end)} (dur√©e: {duration:.1f}s)")
            elif duration >= self.min_ad_duration:
                filtered_intervals.append((start, end))
            else:
                self.logger.info(f"Intervalle rejet√© (trop court): {seconds_to_hms(start)} -> {seconds_to_hms(end)} (dur√©e: {duration:.1f}s < {self.min_ad_duration}s)")
        
        return filtered_intervals

    def analyze_video(self, video_path: str) -> List[Tuple[float, float]]:
        """
        Analyse une vid√©o pour d√©tecter les moments o√π le logo n'est pas pr√©sent.
        Retourne une liste de tuples (start_seconds, end_seconds).
        """
        self.logger.info(f"Analyse de la vid√©o: {video_path}")
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            self.logger.error(f"Impossible d'ouvrir la vid√©o: {video_path}")
            raise ValueError(f"Impossible d'ouvrir la vid√©o: {video_path}")

        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.video_duration = total_frames / fps if fps > 0 else 0

        self.logger.info(f"Dur√©e vid√©o: {seconds_to_hms(self.video_duration)} ({self.video_duration:.0f}s), FPS: {fps:.2f}, Frames: {total_frames}")

        self.detection_history = [] # R√©initialiser pour une nouvelle analyse

        # ========== PREMI√àRE PASSE ==========
        self.logger.info("üîç PREMI√àRE PASSE - √âchantillonnage g√©n√©ral")
        if self.video_duration > 7200: sample_interval_sec_p1 = 45
        elif self.video_duration > 3600: sample_interval_sec_p1 = 30
        elif self.video_duration > 1800: sample_interval_sec_p1 = 20
        else: sample_interval_sec_p1 = 15
        
        # Assurer un sample_interval_frames > 0
        sample_interval_frames_p1 = max(1, int(sample_interval_sec_p1 * fps if fps > 0 else sample_interval_sec_p1))
        self.logger.info(f"Intervalle d'√©chantillonnage premi√®re passe: {sample_interval_sec_p1}s (~{sample_interval_frames_p1} frames)")

        current_frame_num = 0
        frames_analyzed_p1 = 0
        while current_frame_num < total_frames:
            cap.set(cv2.CAP_PROP_POS_FRAMES, current_frame_num)
            ret, frame = cap.read()
            if not ret: break

            timestamp = current_frame_num / fps if fps > 0 else 0
            logo_region = self._extract_logo_region(frame)
            logo_present, confidence = self._is_logo_present(logo_region, frame, analysis_pass=1)
            self.detection_history.append(DetectionPoint(timestamp, current_frame_num, logo_present, confidence, 1))
            
            frames_analyzed_p1 += 1
            current_frame_num += sample_interval_frames_p1
            if frames_analyzed_p1 % 100 == 0:
                progress = (current_frame_num / total_frames) * 100 if total_frames > 0 else 0
                self.logger.info(f"Progression P1: {progress:.1f}% ({frames_analyzed_p1} frames analys√©es)")
        self.logger.info(f"Premi√®re passe termin√©e: {frames_analyzed_p1} points analys√©s.")

        # ========== ANALYSE STATISTIQUE & IDENTIFICATION ZONES SUSPECTES (bas√©e sur Passe 1) ==========
        self.ad_intervals_stats = self._analyze_detection_patterns() # Utilise les d√©tections de passe 1
        suspicious_intervals_for_p2 = self._identify_suspicious_intervals(self.ad_intervals_stats)

        # ========== DEUXI√àME PASSE (Cibl√©e) ==========
        if suspicious_intervals_for_p2:
            self.logger.info("üîé DEUXI√àME PASSE - Analyse cibl√©e sur intervalles suspects")
            second_pass_detections = self._perform_targeted_analysis(cap, suspicious_intervals_for_p2)
            self.detection_history.extend(second_pass_detections)
            self.logger.info(f"Points ajout√©s en deuxi√®me passe: {len(second_pass_detections)}")
        else:
            self.logger.info("‚úÖ Aucun intervalle suspect majeur d√©tect√© - Pas de deuxi√®me passe n√©cessaire ou zones trop petites.")

        # ========== TRAITEMENT FINAL DES R√âSULTATS ==========
        self.logger.info("üìä Traitement final des r√©sultats avec affinement des transitions")
        self.detection_history.sort(key=lambda x: x.timestamp)

        # S'assurer qu'il y a au moins un point de d√©tection pour √©viter les erreurs d'index
        if not self.detection_history:
            self.logger.warning("Aucun point de d√©tection apr√®s les passes d'analyse. Aucune pub ne sera d√©tect√©e.")
            cap.release()
            return []

        precise_ad_intervals = []
        in_ad_segment = False
        current_ad_refined_start = 0.0

        # Ajouter un point de d√©tection synth√©tique au d√©but et √† la fin si n√©cessaire
        # pour faciliter la gestion des transitions aux extr√©mit√©s de la vid√©o.
        # L'√©tat initial est suppos√© √™tre "logo pr√©sent" sauf si la premi√®re d√©tection dit autre chose.
        
        # √âtat du logo avant la premi√®re d√©tection r√©elle. Supposons True (logo pr√©sent).
        # Si la premi√®re d√©tection est tr√®s t√¥t et dit False, cela sera corrig√©.
        last_known_logo_state = True
        last_known_logo_time = 0.0

        # Si la premi√®re d√©tection est une absence de logo d√®s le d√©but
        if not self.detection_history[0].logo_present and self.detection_history[0].timestamp < 1.0 : # Consider <1s as "d√©but"
            last_known_logo_state = False # Commencer en segment pub
            in_ad_segment = True
            current_ad_refined_start = 0.0 # Pub commence √† t=0
            last_known_logo_time = self.detection_history[0].timestamp # Pour la prochaine transition

        # Traiter les points de d√©tection pour trouver les transitions et les affiner
        for i in range(len(self.detection_history)):
            detection = self.detection_history[i]
            
            # Transition: Logo Pr√©sent -> Logo Absent (D√©but de pub)
            if last_known_logo_state and not detection.logo_present:
                refined_start = self._binary_search_logo_transition(
                    cap, last_known_logo_time, detection.timestamp, True # True = logo_present_at_start_of_search
                )
                current_ad_refined_start = refined_start
                in_ad_segment = True
                self.logger.debug(f"Transition P->A: Coarse {seconds_to_hms(detection.timestamp)}, Refined Start {seconds_to_hms(current_ad_refined_start)}")

            # Transition: Logo Absent -> Logo Pr√©sent (Fin de pub)
            elif not last_known_logo_state and detection.logo_present:
                if in_ad_segment: # S'assurer qu'on √©tait bien dans un segment pub
                    refined_end = self._binary_search_logo_transition(
                        cap, last_known_logo_time, detection.timestamp, False # False = logo_absent_at_start_of_search
                    )
                    # S'assurer que refined_end n'est pas avant current_ad_refined_start
                    if refined_end > current_ad_refined_start:
                         precise_ad_intervals.append((current_ad_refined_start, refined_end))
                         self.logger.debug(f"Transition A->P: Coarse {seconds_to_hms(detection.timestamp)}, Refined End {seconds_to_hms(refined_end)}. Interval: [{seconds_to_hms(current_ad_refined_start)}-{seconds_to_hms(refined_end)}]")
                    else:
                        self.logger.warning(f"Fin de pub affin√©e ({seconds_to_hms(refined_end)}) ant√©rieure au d√©but ({seconds_to_hms(current_ad_refined_start)}). Interval ignor√©.")
                    in_ad_segment = False
            
            last_known_logo_state = detection.logo_present
            last_known_logo_time = detection.timestamp

        # G√©rer si la vid√©o se termine pendant une publicit√©
        if in_ad_segment:
            # La pub continue jusqu'√† la fin de la vid√©o.
            # On peut affiner la fin si le dernier point de d√©tection n'est pas exactement self.video_duration
            refined_end = self._binary_search_logo_transition(
                cap, last_known_logo_time, self.video_duration, False # False = logo_absent_at_start
            )
            if refined_end > current_ad_refined_start:
                precise_ad_intervals.append((current_ad_refined_start, refined_end))
                self.logger.debug(f"Fin de vid√©o en pub. Interval: [{seconds_to_hms(current_ad_refined_start)}-{seconds_to_hms(refined_end)}]")
            else:
                 self.logger.warning(f"Fin de pub (vid√©o) affin√©e ({seconds_to_hms(refined_end)}) ant√©rieure au d√©but ({seconds_to_hms(current_ad_refined_start)}). Interval ignor√©.")


        self.logger.info(f"Intervalles d'absence de logo (pr√©cis, avant fusion/filtrage): {len(precise_ad_intervals)}")
        for start, end in precise_ad_intervals:
             self.logger.debug(f"  Brut pr√©cis: {seconds_to_hms(start)} -> {seconds_to_hms(end)}")


        # Fusionner les intervalles pr√©cis qui sont proches
        merged_intervals = self._merge_close_intervals(precise_ad_intervals)
        self.logger.info(f"Apr√®s fusion des intervalles proches: {len(merged_intervals)}")

        # Filtrer par dur√©e minimum (avec exception intro/outro)
        final_intervals = self._filter_minimum_duration_intervals(merged_intervals, self.video_duration)
        self.logger.info(f"Apr√®s filtrage dur√©e min ({self.min_ad_duration}s, sauf intro/outro): {len(final_intervals)}")

        cap.release()

        # Affichage des statistiques finales dans les logs
        total_ad_duration_final = sum(end - start for start, end in final_intervals)
        self.logger.info("="*60)
        self.logger.info("üìà STATISTIQUES FINALES (via LogoDetector)")
        self.logger.info(f"Segments publicitaires finaux d√©tect√©s: {len(final_intervals)}")
        if self.video_duration > 0:
            self.logger.info(f"Dur√©e totale des publicit√©s: {seconds_to_hms(total_ad_duration_final)} ({total_ad_duration_final/self.video_duration*100:.1f}% de la vid√©o)")
        else:
            self.logger.info(f"Dur√©e totale des publicit√©s: {seconds_to_hms(total_ad_duration_final)}")
        self.logger.info(f"Dur√©e totale de la vid√©o: {seconds_to_hms(self.video_duration)}")

        return final_intervals
